
# List of papers for training accelerators

(2017) An automatic RTL compiler for high-throughput FPGA implementation of diverse deep convolutional neural networks([link](https://arxiv.org/pdf/1908.06724.pdf))

(2018) f-CNNx: A Toolflow for Mapping Multiple Convolutional Neural Networks on FPGAs ([link](https://ieeexplore.ieee.org/abstract/document/8533527/))

(2019) Backprop with Approximate Activations for Memory-efficient Network Training([link](https://arxiv.org/abs/1901.07988))

(2019) Training Deep Neural Networks in Low-Precision with High Accuracy Using FPGAs ([link](https://ieeexplore.ieee.org/abstract/document/8977908))

(2019) T-DLA: An Open-source Deep Learning Accelerator for Ternarized DNN Models on Embedded FPGA ([link](https://ieeexplore.ieee.org/abstract/document/8839554))

(2019) Automatic Generation of Multi-Precision Multi-Arithmetic CNN Accelerators for FPGAs ([link](https://ieeexplore.ieee.org/abstract/document/8977872))

(2019) Automatic Compiler Based FPGA Accelerator for CNN Training([link](https://arxiv.org/abs/1908.06724))

(2020) Deep Neural Network Training Accelerator Designs in ASIC and FPGA([link](https://ieeexplore.ieee.org/document/9333063))

(2020) A 2.6 TOPS/W 16-Bit Fixed-Point Convolutional Neural Network Learning Processor in 65-nm CMOS ([link](https://ieeexplore.ieee.org/document/8907458))

(2020) FPRaker: A Processing Element For Accelerating Neural Network Training ([link](https://arxiv.org/abs/2010.08065))

(2021) CHIMERA: A 0.92 TOPS, 2.2 TOPS/W Edge AI Accelerator with 2 MByte On-Chip Foundry Resistive RAM for Efficient Training and Inference ([link](https://ieeexplore.ieee.org/abstract/document/9492347))

(2021) RaPiD: AI Accelerator for Ultra-low Precision Training and Inference ([link](https://ieeexplore.ieee.org/document/9499865))

(2021) 3U-EdgeAI: Ultra-Low Memory Training, Ultra-Low Bitwidth Quantization, and Ultra-Low Latency Acceleration ([link](https://dl.acm.org/doi/abs/10.1145/3453688.3461738))

(2021) FPDeep: Scalable Acceleration of CNN Training on Deeply-Pipelined FPGA Clusters ([link](https://ieeexplore.ieee.org/abstract/document/9110747))

## Overview and Review
(2018) FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review ([link](https://ieeexplore.ieee.org/abstract/document/8594633))

(2020) Challenges in Energy-Efficient Deep Neural Network Training with FPGA ([link](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w28/Tao_Challenges_in_Energy-Efficient_Deep_Neural_Network_Training_With_FPGA_CVPRW_2020_paper.pdf))

(2021) An Overview of Energy-Efficient Hardware Accelerators for On-Device Deep-Neural-Network Training ([link](https://ieeexplore.ieee.org/abstract/document/9569757))
